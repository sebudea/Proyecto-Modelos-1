{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OybfwSK0cfy"
      },
      "source": [
        "# Modelos\n",
        "https://github.com/entron/entity-embedding-rossmann/blob/master/models.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBSBfbqy41AW"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "numpy.random.seed(123)\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "from sklearn import neighbors\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model as KerasModel\n",
        "from keras.layers import Input, Dense, Activation, Reshape\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "def embed_features(X, saved_embeddings_fname):\n",
        "    # f_embeddings = open(\"embeddings_shuffled.pickle\", \"rb\")\n",
        "    f_embeddings = open(saved_embeddings_fname, \"rb\")\n",
        "    embeddings = pickle.load(f_embeddings)\n",
        "\n",
        "    index_embedding_mapping = {1: 0, 2: 1, 4: 2, 5: 3, 6: 4, 7: 5}\n",
        "    X_embedded = []\n",
        "\n",
        "    (num_records, num_features) = X.shape\n",
        "    for record in X:\n",
        "        embedded_features = []\n",
        "        for i, feat in enumerate(record):\n",
        "            feat = int(feat)\n",
        "            if i not in index_embedding_mapping.keys():\n",
        "                embedded_features += [feat]\n",
        "            else:\n",
        "                embedding_index = index_embedding_mapping[i]\n",
        "                embedded_features += embeddings[embedding_index][feat].tolist()\n",
        "\n",
        "        X_embedded.append(embedded_features)\n",
        "\n",
        "    return numpy.array(X_embedded)\n",
        "\n",
        "\n",
        "def split_features(X):\n",
        "    X_list = []\n",
        "\n",
        "    store_index = X[..., [1]]\n",
        "    X_list.append(store_index)\n",
        "\n",
        "    day_of_week = X[..., [2]]\n",
        "    X_list.append(day_of_week)\n",
        "\n",
        "    promo = X[..., [3]]\n",
        "    X_list.append(promo)\n",
        "\n",
        "    year = X[..., [4]]\n",
        "    X_list.append(year)\n",
        "\n",
        "    month = X[..., [5]]\n",
        "    X_list.append(month)\n",
        "\n",
        "    day = X[..., [6]]\n",
        "    X_list.append(day)\n",
        "\n",
        "    State = X[..., [7]]\n",
        "    X_list.append(State)\n",
        "\n",
        "    return X_list\n",
        "\n",
        "\n",
        "class Model(object):\n",
        "\n",
        "    def evaluate(self, X_val, y_val):\n",
        "        assert(min(y_val) > 0)\n",
        "        guessed_sales = self.guess(X_val)\n",
        "        relative_err = numpy.absolute((y_val - guessed_sales) / y_val)\n",
        "        result = numpy.sum(relative_err) / len(y_val)\n",
        "        return result\n",
        "\n",
        "\n",
        "class LinearModel(Model):\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val):\n",
        "        super().__init__()\n",
        "        self.clf = linear_model.LinearRegression()\n",
        "        self.clf.fit(X_train, numpy.log(y_train))\n",
        "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
        "\n",
        "    def guess(self, feature):\n",
        "        return numpy.exp(self.clf.predict(feature))\n",
        "\n",
        "\n",
        "class RF(Model):\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val):\n",
        "        super().__init__()\n",
        "        self.clf = RandomForestRegressor(n_estimators=200, verbose=True, max_depth=35, min_samples_split=2,\n",
        "                                         min_samples_leaf=1)\n",
        "        self.clf.fit(X_train, numpy.log(y_train))\n",
        "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
        "\n",
        "    def guess(self, feature):\n",
        "        return numpy.exp(self.clf.predict(feature))\n",
        "\n",
        "\n",
        "class SVM(Model):\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val):\n",
        "        super().__init__()\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.__normalize_data()\n",
        "        self.clf = SVR(kernel='linear', degree=3, gamma='auto', coef0=0.0, tol=0.001,\n",
        "                       C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
        "\n",
        "        self.clf.fit(self.X_train, numpy.log(self.y_train))\n",
        "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
        "\n",
        "    def __normalize_data(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.X_train = self.scaler.fit_transform(self.X_train)\n",
        "\n",
        "    def guess(self, feature):\n",
        "        return numpy.exp(self.clf.predict(feature))\n",
        "\n",
        "\n",
        "class XGBoost(Model):\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val):\n",
        "        super().__init__()\n",
        "        dtrain = xgb.DMatrix(X_train, label=numpy.log(y_train))\n",
        "        evallist = [(dtrain, 'train')]\n",
        "        param = {'nthread': -1,\n",
        "                 'max_depth': 7,\n",
        "                 'eta': 0.02,\n",
        "                 'silent': 1,\n",
        "                 'objective': 'reg:linear',\n",
        "                 'colsample_bytree': 0.7,\n",
        "                 'subsample': 0.7}\n",
        "        num_round = 3000\n",
        "        self.bst = xgb.train(param, dtrain, num_round, evallist)\n",
        "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
        "\n",
        "    def guess(self, feature):\n",
        "        dtest = xgb.DMatrix(feature)\n",
        "        return numpy.exp(self.bst.predict(dtest))\n",
        "\n",
        "\n",
        "class HistricalMedian(Model):\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val):\n",
        "        super().__init__()\n",
        "        self.history = {}\n",
        "        self.feature_index = [1, 2, 3, 4]\n",
        "        for x, y in zip(X_train, y_train):\n",
        "            key = tuple(x[self.feature_index])\n",
        "            self.history.setdefault(key, []).append(y)\n",
        "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
        "\n",
        "    def guess(self, features):\n",
        "        features = numpy.array(features)\n",
        "        features = features[:, self.feature_index]\n",
        "        guessed_sales = [numpy.median(self.history[tuple(feature)]) for feature in features]\n",
        "        return numpy.array(guessed_sales)\n",
        "\n",
        "\n",
        "class KNN(Model):\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val):\n",
        "        super().__init__()\n",
        "        self.normalizer = Normalizer()\n",
        "        self.normalizer.fit(X_train)\n",
        "        self.clf = neighbors.KNeighborsRegressor(n_neighbors=10, weights='distance', p=1)\n",
        "        self.clf.fit(self.normalizer.transform(X_train), numpy.log(y_train))\n",
        "        print(\"Result on validation data: \", self.evaluate(self.normalizer.transform(X_val), y_val))\n",
        "\n",
        "    def guess(self, feature):\n",
        "        return numpy.exp(self.clf.predict(self.normalizer.transform(feature)))\n",
        "\n",
        "\n",
        "class NN_with_EntityEmbedding(Model):\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val):\n",
        "        super().__init__()\n",
        "        self.epochs = 10\n",
        "        self.checkpointer = ModelCheckpoint(filepath=\"best_model_weights.hdf5\", verbose=1, save_best_only=True)\n",
        "        self.max_log_y = max(numpy.max(numpy.log(y_train)), numpy.max(numpy.log(y_val)))\n",
        "        self.__build_keras_model()\n",
        "        self.fit(X_train, y_train, X_val, y_val)\n",
        "\n",
        "    def preprocessing(self, X):\n",
        "        X_list = split_features(X)\n",
        "        return X_list\n",
        "\n",
        "    def __build_keras_model(self):\n",
        "        input_store = Input(shape=(1,))\n",
        "        output_store = Embedding(1115, 10, name='store_embedding')(input_store)\n",
        "        output_store = Reshape(target_shape=(10,))(output_store)\n",
        "\n",
        "        input_dow = Input(shape=(1,))\n",
        "        output_dow = Embedding(7, 6, name='dow_embedding')(input_dow)\n",
        "        output_dow = Reshape(target_shape=(6,))(output_dow)\n",
        "\n",
        "        input_promo = Input(shape=(1,))\n",
        "        output_promo = Dense(1)(input_promo)\n",
        "\n",
        "        input_year = Input(shape=(1,))\n",
        "        output_year = Embedding(3, 2, name='year_embedding')(input_year)\n",
        "        output_year = Reshape(target_shape=(2,))(output_year)\n",
        "\n",
        "        input_month = Input(shape=(1,))\n",
        "        output_month = Embedding(12, 6, name='month_embedding')(input_month)\n",
        "        output_month = Reshape(target_shape=(6,))(output_month)\n",
        "\n",
        "        input_day = Input(shape=(1,))\n",
        "        output_day = Embedding(31, 10, name='day_embedding')(input_day)\n",
        "        output_day = Reshape(target_shape=(10,))(output_day)\n",
        "\n",
        "        input_germanstate = Input(shape=(1,))\n",
        "        output_germanstate = Embedding(12, 6, name='state_embedding')(input_germanstate)\n",
        "        output_germanstate = Reshape(target_shape=(6,))(output_germanstate)\n",
        "\n",
        "        input_model = [input_store, input_dow, input_promo,\n",
        "                       input_year, input_month, input_day, input_germanstate]\n",
        "\n",
        "        output_embeddings = [output_store, output_dow, output_promo,\n",
        "                             output_year, output_month, output_day, output_germanstate]\n",
        "\n",
        "        output_model = Concatenate()(output_embeddings)\n",
        "        output_model = Dense(1000, kernel_initializer=\"uniform\")(output_model)\n",
        "        output_model = Activation('relu')(output_model)\n",
        "        output_model = Dense(500, kernel_initializer=\"uniform\")(output_model)\n",
        "        output_model = Activation('relu')(output_model)\n",
        "        output_model = Dense(1)(output_model)\n",
        "        output_model = Activation('sigmoid')(output_model)\n",
        "\n",
        "        self.model = KerasModel(inputs=input_model, outputs=output_model)\n",
        "\n",
        "        self.model.compile(loss='mean_absolute_error', optimizer='adam')\n",
        "\n",
        "    def _val_for_fit(self, val):\n",
        "        val = numpy.log(val) / self.max_log_y\n",
        "        return val\n",
        "\n",
        "    def _val_for_pred(self, val):\n",
        "        return numpy.exp(val * self.max_log_y)\n",
        "\n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "        self.model.fit(self.preprocessing(X_train), self._val_for_fit(y_train),\n",
        "                       validation_data=(self.preprocessing(X_val), self._val_for_fit(y_val)),\n",
        "                       epochs=self.epochs, batch_size=128,\n",
        "                       # callbacks=[self.checkpointer],\n",
        "                       )\n",
        "        # self.model.load_weights('best_model_weights.hdf5')\n",
        "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
        "\n",
        "    def guess(self, features):\n",
        "        features = self.preprocessing(features)\n",
        "        result = self.model.predict(features).flatten()\n",
        "        return self._val_for_pred(result)\n",
        "\n",
        "\n",
        "class NN(Model):\n",
        "\n",
        "    def __init__(self, X_train, y_train, X_val, y_val):\n",
        "        super().__init__()\n",
        "        self.epochs = 10\n",
        "        self.checkpointer = ModelCheckpoint(filepath=\"best_model_weights.hdf5\", verbose=1, save_best_only=True)\n",
        "        self.max_log_y = max(numpy.max(numpy.log(y_train)), numpy.max(numpy.log(y_val)))\n",
        "        self.__build_keras_model()\n",
        "        self.fit(X_train, y_train, X_val, y_val)\n",
        "\n",
        "    def __build_keras_model(self):\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Dense(1000, kernel_initializer=\"uniform\", input_dim=1183))\n",
        "        self.model.add(Activation('relu'))\n",
        "        self.model.add(Dense(500, kernel_initializer=\"uniform\"))\n",
        "        self.model.add(Activation('relu'))\n",
        "        self.model.add(Dense(1))\n",
        "        self.model.add(Activation('sigmoid'))\n",
        "\n",
        "        self.model.compile(loss='mean_absolute_error', optimizer='adam')\n",
        "\n",
        "    def _val_for_fit(self, val):\n",
        "        val = numpy.log(val) / self.max_log_y\n",
        "        return val\n",
        "\n",
        "    def _val_for_pred(self, val):\n",
        "        return numpy.exp(val * self.max_log_y)\n",
        "\n",
        "    def fit(self, X_train, y_train, X_val, y_val):\n",
        "        self.model.fit(X_train, self._val_for_fit(y_train),\n",
        "                       validation_data=(X_val, self._val_for_fit(y_val)),\n",
        "                       epochs=self.epochs, batch_size=128,\n",
        "                       # callbacks=[self.checkpointer],\n",
        "                       )\n",
        "        # self.model.load_weights('best_model_weights.hdf5')\n",
        "        print(\"Result on validation data: \", self.evaluate(X_val, y_val))\n",
        "\n",
        "    def guess(self, features):\n",
        "        result = self.model.predict(features).flatten()\n",
        "        return self._val_for_pred(result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
